{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Walk Through Forpus\n",
    "\n",
    "[Forpus](https://severinsimmler.github.io/forpus) is a Python library for processing plain text corpora to various corpus formats. In most cases, each NLP tool uses its own idiosyncratic input format. This library helps you to convert a corpus very easy to the desired format.\n",
    "\n",
    "To install Forpus, run the following command in your command-line:\n",
    "\n",
    "```bash\n",
    "pip install forpus\n",
    "```\n",
    "\n",
    "You will need a directory containing `.txt` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "try:\n",
    "    from forpus import forpus\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    sys.path.insert(0, str(Path('.').absolute().parent))\n",
    "    from forpus import forpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = Path('..', 'corpus')\n",
    "FNAME_PATTERN = '{author}_{title}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Converting to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = forpus.Corpus(source=SOURCE,\n",
    "                       target='json',\n",
    "                       fname_pattern=FNAME_PATTERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Calling the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Checking the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mary_doc3': {'author': 'mary', 'title': 'doc3', 'text': 'Mary has written the third and last document, but this is also pretty nice.\\n'}, 'peter_doc1': {'author': 'peter', 'title': 'doc1', 'text': \"This is the first document. It's written by Peter. And it contains a lot of words.\\n\"}, 'paul_doc2': {'author': 'paul', 'title': 'doc2', 'text': 'There is also a second document. This one is by Paul. Furthermore, this also contains a lot of tokens.\\n'}}\n"
     ]
    }
   ],
   "source": [
    "with Path('json', 'corpus.json').open('r', encoding='utf-8') as file:\n",
    "    print(json.load(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting to LDA-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = forpus.Corpus(source=SOURCE,\n",
    "                       target='ldac',\n",
    "                       fname_pattern=FNAME_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(document):\n",
    "    return re.compile('\\w+').findall(document)\n",
    "\n",
    "def drop_stopwords(tokens, stopwords=['the', 'and']):\n",
    "    return [token for token in tokens if token not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus.to_ldac(tokenizer=tokenizer,\n",
    "               drop_stopwords=drop_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.ldac:\n",
      "12 0:1 1:1 2:1 3:1 4:1 5:1 6:1 7:1 8:1 9:1 10:1 11:1\n",
      "16 12:1 8:1 13:1 5:1 14:1 15:1 2:1 16:1 17:1 18:1 19:1 20:1 21:1 22:1 23:1 24:1\n",
      "16 25:1 8:2 9:2 21:2 26:1 5:1 12:1 27:1 16:1 28:1 29:1 7:1 20:1 22:1 23:1 30:1\n",
      "\n",
      "corpus.vocab:\n",
      "Mary\n",
      "has\n",
      "written\n",
      "third\n",
      "last\n",
      "document\n",
      "but\n",
      "this\n",
      "is\n",
      "also\n",
      "pretty\n",
      "nice\n",
      "This\n",
      "first\n",
      "It\n",
      "s\n",
      "by\n",
      "Peter\n",
      "And\n",
      "it\n",
      "contains\n",
      "a\n",
      "lot\n",
      "of\n",
      "words\n",
      "There\n",
      "second\n",
      "one\n",
      "Paul\n",
      "Furthermore\n",
      "tokens\n",
      "\n",
      "corpus.metadata (a simple CSV-file):\n",
      ",author,title\n",
      "../corpus/mary_doc3.txt,mary,doc3\n",
      "../corpus/peter_doc1.txt,peter,doc1\n",
      "../corpus/paul_doc2.txt,paul,doc2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Path('ldac', 'corpus.ldac').open('r', encoding='utf-8') as file:\n",
    "    print('corpus.ldac:\\n{0}\\n'.format(file.read()))\n",
    "\n",
    "with Path('ldac', 'corpus.vocab').open('r', encoding='utf-8') as file:\n",
    "    print('corpus.vocab:\\n{0}\\n'.format(file.read()))\n",
    "\n",
    "with Path('ldac', 'corpus.metadata').open('r', encoding='utf-8') as file:\n",
    "    print('corpus.metadata (a simple CSV-file):\\n{0}'.format(file.read()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
